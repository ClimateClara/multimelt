{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206576a1-cfb4-419f-bae9-85a2b3fe4542",
   "metadata": {},
   "source": [
    "\n",
    "Created on Fri Jun 4 15:50 2020 (Author: Clara Burgard)\n",
    "\n",
    "This is an example script to convert the 2D fields (stereographic grid) of \n",
    "- the conservative temperature to potential temperature \n",
    "- the absolute salinity to practical salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import gsw\n",
    "import matplotlib.pyplot as plt\n",
    "import multimelt.useful_functions as uf\n",
    "import multimelt.T_S_profile_functions as tspf\n",
    "import multimelt.melt_functions as meltf\n",
    "\n",
    "import distributed\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa61bd58-b5ae-47f1-bd15-1510c317d472",
   "metadata": {},
   "source": [
    "DEPENDING ON THE SIZE OF YOUR DATA, THIS WILL REQUIRE USING DASK\n",
    "\n",
    "For example, open a client like this: (check that the number of workers is lower or equal to the number of cores you use and the memory limit is equal to the memory of your cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = distributed.Client(n_workers=4, dashboard_address=':8795', local_directory='/tmp', memory_limit='6GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "client # check what's happening with the client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-median",
   "metadata": {},
   "source": [
    "READ IN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath_data = # path to folder where you stored the file that defines the depth of your depth coordinate and your files with 2D fields of temperature and salinity\n",
    "inputpath_isf = # path to folder where you stored the masks created earlier\n",
    "outputpath_profiles = # path to folder where you want to store your output\n",
    "\n",
    "# make the domain a little smaller to make the computation even more efficient\n",
    "map_lim = [-3000000,3000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file that defines the depth of your depth coordinate\n",
    "file_mask = xr.open_mfdataset(inputpath_data+'mask_depth_coord_Ant_stereo.nc') \n",
    "# read mask file created earlier\n",
    "file_isf = xr.open_mfdataset(inputpath_isf+'nemo_5km_isf_masks_and_info_and_distance_new_oneFRIS.nc', chunks={'x': 533, 'y': 533}) \n",
    "# make domain a little smaller\n",
    "file_isf_cut = uf.cut_domain_stereo(file_isf, map_lim, map_lim)\n",
    "\n",
    "# 2D field of temperature and salinity for just one time step (to define domains where there is open ocean)\n",
    "file_TS_orig  = xr.open_mfdataset(inputpath_data+'variables_of_interest_2000_Ant_stereo.nc', chunks={'x': 600, 'y': 600})\n",
    "# make domain a little smaller\n",
    "file_TS_orig_cut = uf.cut_domain_stereo(file_TS_orig, map_lim, map_lim).squeeze().drop('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# longitude and latitude\n",
    "lon = file_isf_cut['longitude']\n",
    "lat = file_isf_cut['latitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f5088-00aa-48aa-a183-8d5464adfbe7",
   "metadata": {},
   "source": [
    "FORMAT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc06a997-fd52-47ba-a4b4-6b4e5739f305",
   "metadata": {},
   "source": [
    "Prepare temperature and salinity fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all 2D temperature and salinity files (all years in folder) and concatenate them\n",
    "ts_files = list(sorted(glob.glob(inputpath_data+'variables_of_interest_*_Ant_stereo.nc')))\n",
    "ds_ts  = xr.open_mfdataset(ts_files, concat_dim='new_time', combine='nested', chunks={'x': 600, 'y': 600})\n",
    "ds_ts = ds_ts[['votemper', 'vosaline', 'sosst']] # keep conservative temperature, absolute salinity and sea surface temperature\n",
    "\n",
    "# define the years on the time axis (this is necessary if the yearly separate files all have year \"1\" as coordinate\n",
    "yy_start = 1989\n",
    "yy_end = 2018\n",
    "ds_ts = ds_ts.squeeze('time') \n",
    "ds_ts = ds_ts.rename({'new_time': 'time'})\n",
    "ds_ts = ds_ts.assign_coords(time=np.arange(yy_start, yy_end+1)) \n",
    "\n",
    "# make domain a little smaller\n",
    "ds_ts_cut = uf.cut_domain_stereo(ds_ts, map_lim, map_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-replica",
   "metadata": {},
   "source": [
    "Prepare the depth axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "nemo_depth = np.round(file_mask['gdept_0'].squeeze(dim=['lon','lat']), 3) # round to mm scale - should be enough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-thread",
   "metadata": {},
   "source": [
    "Cut out the temperature and salinity and assign the new depth axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_temp_saline_input = ds_ts_cut[['votemper', 'vosaline']]\n",
    "ds_temp_saline_input = ds_temp_saline_input.rename({'votemper': 'temperature', 'vosaline': 'salinity'})\n",
    "ds_temp_saline_input = ds_temp_saline_input.rename({'deptht': 'depth'})\n",
    "ds_temp_saline_input['depth'] = np.round(ds_temp_saline_input.depth, 3)\n",
    "ds_temp_saline_input = ds_temp_saline_input.assign_coords(depth=nemo_depth.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only points of open ocean\n",
    "# where there is an SST, it is ocean without ice shelf cavity\n",
    "mask_ocean = np.isfinite(file_TS_orig_cut['sosst']).squeeze()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-wednesday",
   "metadata": {},
   "source": [
    "CONVERT CONSERVATIVE TEMPERATURE TO POTENTIAL TEMPERATURE AND ABSOLUTE SALINITY TO PRACTICAL SALINITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_temp_saline_input['theta_ocean'] = xr.apply_ufunc(gsw.pt_from_CT, ds_temp_saline_input['salinity'].where(mask_ocean), ds_temp_saline_input['temperature'].where(mask_ocean), dask = 'allowed')\n",
    "ds_temp_saline_input['salinity_ocean'] = xr.apply_ufunc(gsw.SP_from_SA, ds_temp_saline_input['salinity'].where(mask_ocean), ds_temp_saline_input['depth'], lon, lat, dask = 'allowed')\n",
    "ds_temp_saline_output = ds_temp_saline_input[['theta_ocean', 'salinity_ocean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-efficiency",
   "metadata": {},
   "source": [
    "Prepare to write the results to multiple files (1 per year) - this is where dask comes into play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_datasets = list(tspf.split_by_chunks(ds_temp_saline_output.unify_chunks(),'time'))\n",
    "paths = [tspf.create_filepath(ds, 'T_S_theta_ocean_corrected', inputpath_profiles, ds.time[0].values) for ds in yearly_datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-genius",
   "metadata": {},
   "source": [
    "This takes approximately 1 min per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.save_mfdataset(datasets=yearly_datasets, paths=paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ice_shelf_mask",
   "language": "python",
   "name": "ice_shelf_mask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
